# Awesome Incremental / Continual / Lifelong Generative Learning
[![Awesome](https://awesome.re/badge.svg)](#pushpin-outline)
[<img src="https://img.shields.io/badge/Contributions-Welcome-278ea5" alt=""/>](#books-contribute-chinese-version)

## :pushpin: Outline
[:closed_book: Paper](#closed_book-paper)

&emsp; [2024](#2024) | [2023](#2023) | [2022](#2022) | [2021](#2021) | [2020](#2020) | [2019](#2019) | [2018](#2018) | [2017](#2017) | [Pre-2017](#pre-2017) 

[:clap: Contribute](#clap-contribute-chinese-version)

---
## :closed_book: Paper
### 2024
- eTag: Class-Incremental Learning via Embedding Distillation and Task-Oriented Generation (**AAAI 2024**) [[paper](https://ojs.aaai.org/index.php/AAAI/article/view/29153)] [[code](https://github.com/libo-huang/eTag)] 
- SDDGR: Stable Diffusion-based Deep Generative Replay for Class Incremental Object Detection (**CVPR 2024**) [[paper](https://openaccess.thecvf.com/content/CVPR2024/html/Kim_SDDGR_Stable_Diffusion-based_Deep_Generative_Replay_for_Class_Incremental_Object_CVPR_2024_paper.html)]
- Generative Multi-modal Models are Good Class Incremental Learners (**CVPR 2024**) [[paper](https://openaccess.thecvf.com/content/CVPR2024/html/Cao_Generative_Multi-modal_Models_are_Good_Class_Incremental_Learners_CVPR_2024_paper.html)] [[code](https://github.com/DoubleClass/GMM)]
- Online Task-Free Continual Generative and Discriminative Learning via Dynamic Cluster Memory (**CVPR 2024**) [[paper](https://openaccess.thecvf.com/content/CVPR2024/html/Ye_Online_Task-Free_Continual_Generative_and_Discriminative_Learning_via_Dynamic_Cluster_CVPR_2024_paper.html)] [[code](https://github.com/dtuzi123/DCM)]
- COPAL: Continual Pruning in Large Language Generative Models (**ICML 2024**) [[paper](https://openreview.net/forum?id=Lt8Lk7IQ5b)]
- Continual Diffusion: Continual Customization of Text-to-Image Diffusion with C-LoRA (**TMLR 2024**) [[paper](https://openreview.net/forum?id=TZdEgwZ6f3)]
- KFC: Knowledge Reconstruction and Feedback Consolidation Enable Efficient and Effective Continual Generative Learning (**ICLR-tiny paper 2024**) [[paper](https://openreview.net/pdf?id=pVTcR8ig3R)] [[code](https://github.com/libo-huang/KFC)]


### 2023
- Lfs-gan: Lifelong few-shot image generation (**ICCV 2023**) [[paper](https://openaccess.thecvf.com/content/ICCV2023/html/Seo_LFS-GAN_Lifelong_Few-Shot_Image_Generation_ICCV_2023_paper.html)] [[code](https://github.com/KHU-AGI/LFS-GAN)]
- Generating Instance-level Prompts for Rehearsal-free Continual Learning (**ICCV 2023**) [[paper](https://openaccess.thecvf.com/content/ICCV2023/html/Jung_Generating_Instance-level_Prompts_for_Rehearsal-free_Continual_Learning_ICCV_2023_paper.html)] [[code](https://github.com/naver-ai/dap-cl)]
- When Prompt-based Incremental Learning Does Not Meet Strong Pretraining (**ICCV 2023**) [[paper](https://openaccess.thecvf.com/content/ICCV2023/html/Tang_When_Prompt-based_Incremental_Learning_Does_Not_Meet_Strong_Pretraining_ICCV_2023_paper.html)] [[code](https://github.com/TOM-tym/APG)]
- What does a platypus look like? Generating customized prompts for zero-shot image classification (**ICCV 2023**) [[paper](https://openaccess.thecvf.com/content/ICCV2023/html/Pratt_What_Does_a_Platypus_Look_Like_Generating_Customized_Prompts_for_ICCV_2023_paper.html)] [[code](https://github.com/sarahpratt/CuPL)]
- Poisoning Generative Replay in Continual Learning to Promote Forgetting (**ICML 2023**) [[paper](https://proceedings.mlr.press/v202/kang23c.html)] [[code](https://www.dropbox.com/scl/fo/ae954h8tsjd6z138x7yf5/ACVvowDAq4C9cjJgUXuNJKw?rlkey=nhqo08bd7tzoxd0g6w2y5oijc&e=1&st=an4xuj5w&dl=0)]
- DDGR: Continual Learning with Deep Diffusion-based Generative Replay (**ICML 2023**) [[paper](https://proceedings.mlr.press/v202/gao23e)] [[code](https://github.com/xiaocangshengGR/DDGR)]
- Selective Amnesia: A Continual Learning Approach to Forgetting in Deep Generative Models (**NeurIPS 2023**) [[paper](https://proceedings.neurips.cc/paper_files/paper/2023/hash/376276a95781fa17c177b1ccdd0a03ac-Abstract-Conference.html)] [[code](https://github.com/clear-nus/selective-amnesia)]
- Better Generative Replay for Continual Federated Learning (**ICLR 2023**) [[paper](https://openreview.net/forum?id=cRxYWKiTan)] [[code](https://github.com/daiqing98/FedCIL)]
- Generative negative replay for continual learning (**Neural Network 2023**) [[paper](https://www.sciencedirect.com/science/article/pii/S0893608023001235)] [[code](https://openreview.net/forum?id=MWQCPYSJRN)]


### 2022
- Generative Negative Text Replay for Continual Vision-Language Pretraining (**ECCV 2022**) [[paper](https://www.ecva.net/papers/eccv_2022/papers_ECCV/papers/136960022.pdf)]
- Continual Sequence Generation with Adaptive Compositional Modules (**ACL 2022**) [[paper](https://aclanthology.org/2022.acl-long.255/)] [[code](https://github.com/SALT-NLP/Adaptive-Compositional-Modules)]
- Unified probabilistic deep continual learning through generative replay and open set recognition (**Journal of Image 2022**) [[paper](https://d1wqtxts1xzle7.cloudfront.net/92524318/pdf-libre.pdf?1665928933=&response-content-disposition=inline%3B+filename%3DUnified_Probabilistic_Deep_Continual_Lea.pdf&Expires=1722779706&Signature=LnvZgOp795QVK-4SzuUAwZLwdvIROMY~Mbzb3Q8e8cHOIwFitPMdh7wlO3fk2xY-tpu60g-KT3U3F-9oWy-X52xJ0~Dwrvet-pCZkoJffvwlfPO1rjsT1y~tpRj7O7CnU-hycrdmYo3rhg~IKHYIwUYEgYOvi1wTsj2Zl0iVMbGfJwigu3OMh0WvEgsXzHTAf9PUj~wqk8zYrUfrxjrY~SfUcqV2Z7SfAwGII8Fmixa2NiUzxRBku2CODulBNSr7hEjI52P-UIfJ3YJm42la-oS1pq9jfNZ4VUmHtO2E3V3T2UnDVv5RGjYSFyCkpyf4wHw5TWJW7atAUev1Q1pugQ__&Key-Pair-Id=APKAJLOHF5GGSLRBV4ZA)] [[code](https://github.com/MrtnMndt/OpenVAE_ContinualLearning)]
- Continual Learning with Foundation Models: An Empirical Study of Latent Replay (**CoLLAs 2022**) [[paper](https://proceedings.mlr.press/v199/ostapenko22a.html)] [[code](https://github.com/oleksost/latent_CL)]

### 2021
- Hyper-LifelongGAN: Scalable Lifelong Learning for Image Conditioned Generation (**CVPR 2021**) [[paper](https://openaccess.thecvf.com/content/CVPR2021/html/Zhai_Hyper-LifelongGAN_Scalable_Lifelong_Learning_for_Image_Conditioned_Generation_CVPR_2021_paper.html)]
- Efficient Feature Transformations for Discriminative and Generative Continual Learning (**CVPR 2021**) [[paper](https://openaccess.thecvf.com/content/CVPR2021/html/Verma_Efficient_Feature_Transformations_for_Discriminative_and_Generative_Continual_Learning_CVPR_2021_paper.html)] [[code](https://github.com/vkverma01/EFT)]
- Always Be Dreaming: A New Approach for Data-Free Class-Incremental Learning (**ICCV 2021**) [[paper](https://openaccess.thecvf.com/content/ICCV2021/html/Smith_Always_Be_Dreaming_A_New_Approach_for_Data-Free_Class-Incremental_Learning_ICCV_2021_paper.html)] [[code](https://github.com/GT-RIPL/AlwaysBeDreaming-DFCIL)]
- CAM-GAN: Continual Adaptation Modules for Generative Adversarial Networks (**NeurIPS 2021**) [[paper](https://proceedings.neurips.cc/paper/2021/hash/8073bd4ed0fe0c330290c58056a2cd5e-Abstract.html)] [[code](https://github.com/sakshivarshney/CAM-GAN)]
- Generative vs. Discriminative: Rethinking The Meta-Continual Learning (**NeurIPS 2021**) [[paper](https://papers.nips.cc/paper/2021/hash/b4e267d84075f66ebd967d95331fcc03-Abstract.html)] [[code](https://github.com/aminbana/GeMCL)]
- Generative Feature Replay with Orthogonal Weight Modification for Continual Learning (**IJCNN 2021**) [[paper](https://ieeexplore.ieee.org/abstract/document/9534437/)]
 


### 2020
- Dreaming to distill: Data-free knowledge transfer via deepinversion (**CVPR 2020**) [[paper](https://openaccess.thecvf.com/content_CVPR_2020/html/Yin_Dreaming_to_Distill_Data-Free_Knowledge_Transfer_via_DeepInversion_CVPR_2020_paper.html)] [[code](https://github.com/NVlabs/DeepInversion)]
- Piggyback GAN: Efficient Lifelong Learning for Image Conditioned Generation (**ECCV 22020**) [[paper](https://www.ecva.net/papers/eccv_2020/papers_ECCV/papers/123660392.pdf)]
- GAN memory with no forgetting (**NeurIPS 2020**) [[paper](https://papers.nips.cc/paper/2020/file/bf201d5407a6509fa536afc4b380577e-Paper.pdf)] [[code](https://github.com/MiaoyunZhao/GANmemory_LifelongLearning)]
- Brain-inspired replay for continual learning with artificial neural networks (**Nature Communications 2020**) [[paper](https://www.nature.com/articles/s41467-020-17866-2.pdf)] [[code](https://github.com/GMvandeVen/brain-inspired-replay)]
- Lifelong generative modeling (**Neurocomputing 2020**) [[paper](https://github.com/jramapuram/LifelongVAE)] [[code](https://www.sciencedirect.com/science/article/pii/S0925231220303623#bib0115)]
- Catastrophic forgetting and mode collapse in GANs (**IJCNN 2020**) [[paper](https://ieeexplore.ieee.org/abstract/document/9207181)] [[code](https://github.com/htt210/CatastrophicGANCode)]
- Continual Learning: Tackling Catastrophic Forgetting in Deep Neural Networks with Replay Processes (**PhD Thesis**) [[paper](https://arxiv.org/pdf/2007.00487)]
- Brain-like replay for continual learning with artificial neural networks (**ICLR-W 2020**) [[paper](https://baicsworkshop.github.io/pdf/BAICS_8.pdf)]


### 2019
- Learning to remember: A synaptic plasticity driven framework for continual learning (**CVPR 2019**) [[paper](https://openaccess.thecvf.com/content_CVPR_2019/html/Ostapenko_Learning_to_Remember_A_Synaptic_Plasticity_Driven_Framework_for_Continual_CVPR_2019_paper.html)] [[code](https://github.com/SAP-archive/machine-learning-dgm)]
- Closed-loop Memory GAN for Continual Learning (**IJCAI 2019**) [[paper](https://www.ijcai.org/proceedings/2019/0462.pdf)]
- Lifelong GAN: Continual learning for conditional image generation (**ICCV 2019**) [[paper](https://openaccess.thecvf.com/content_ICCV_2019/html/Zhai_Lifelong_GAN_Continual_Learning_for_Conditional_Image_Generation_ICCV_2019_paper.html)]
- Complementary Learning for Overcoming Catastrophic Forgetting Using Experience Replay (**IJCAI 2019**) [[paper](https://www.ijcai.org/proceedings/2019/0463.pdf)]
- Continual Unsupervised Representation Learning (**NeurIPS 2019**) [[paper](https://proceedings.neurips.cc/paper/2019/hash/861578d797aeb0634f77aff3f488cca2-Abstract.html)] [[code](https://github.com/google-deepmind/deepmind-research/tree/master/curl)]
- Generative Models from the perspective of Continual Learning (**IJCNN 2019**) [[paper](https://ieeexplore.ieee.org/abstract/document/8851986/)] [[code](https://github.com/TLESORT/Generative_Continual_Learning)]
- Marginal replay vs conditional replay for continual learning (**ICANN 2019**) [[paper](https://arxiv.org/pdf/1810.12069)]



### 2018
- Variational Continual Learning (**ICLR 2018**) [[paper](https://openreview.net/pdf?id=BkQqq0gRb)] [[code](https://github.com/nvcuong/variational-continual-learning)]
- Memorization precedes generation: Learning unsupervised GANs with memory networks (**ICLR 2018**) [[paper](https://openreview.net/pdf?id=rkO3uTkAZ)] [[code](https://github.com/whyjay/memoryGAN)]
- Memory Replay GANs: Learning to Generate New Categories without Forgetting (**NeurIPS 2018**) [[paper](https://proceedings.neurips.cc/paper/2018/hash/a57e8915461b83adefb011530b711704-Abstract.html)] [[code](https://github.com/WuChenshen/MeRGAN)]
- Exemplar-Supported Generative Reproduction for Class Incremental Learning (**BMVC 2018**) [[paper](http://bmvc2018.org/contents/papers/0325.pdf)] [[code](https://github.com/TonyPod/ESGR)]
- Improving and Understanding Variational Continual Learning (**NeurIPS-W 2018**) [[paper](https://arxiv.org/pdf/1905.02099)] [[code](https://github.com/nvcuong/variational-continual-learning/tree/master/improved_ddm)]
- Continual Classification Learning Using Generative Models (**NeurIPS-W 2018**) [[paper](https://arodes.hes-so.ch/record/4159?ln=en&v=pdf)]
- Self-Supervised GAN to Counter Forgetting (**NeurIPS-W 2018**) [[paper](https://arxiv.org/pdf/1810.11598)]
- Generative replay with feedback connections as a general strategy for continual learning (**arXiv 2018**) [[paper](https://arxiv.org/abs/1809.10635)] [[code](https://github.com/GMvandeVen/continual-learning)]

### 2017
- Continual Learning with Deep Generative Replay (**NIPS 2017**) [[paper](https://proceedings.neurips.cc/paper/2017/hash/0efbe98067c6c73dba1250d2beaa81f9-Abstract.html)]
- Continual Learning in Generative Adversarial Nets (**arXiv 2017**) [[paper](https://arxiv.org/pdf/1705.08395)]



### Pre-2017
- Catastrophic Forgetting, Rehearsal and Pseudorehearsal (**Connection Science 1995**) [[paper](https://citeseerx.ist.psu.edu/document?repid=rep1&type=pdf&doi=5ac423a83b4321b43249224fcc528bb70e086826)]



---
## :clap: Contribute [[chinese version](http://t.csdnimg.cn/S1rvo)]
**1. Fork the Repository:** Click on the `Fork` button located in the top-right corner to create a copy of the repository in your personal GitHub account.

**2. Create a New Branch:** In your forked repository, create a new branch (e.g., "libo") by using the branch selector button near the top-left (usually labeled `master` or `main`).

**3. Make Your Changes:** Switch to your new branch using the same branch selector. Then, click the `Edit file` button at the top right to make your changes. Add entries in the following format:
  ```bash
  - paper_name (**journal/conference_name year**) [[paper](online_paper_link)] [[code](online_code_link)]
  ```

**4. Commit Changes:** Save your changes by clicking the `Commit changes` button in the upper-right corner. Enter a commit message (e.g., "add 1 cvpr'24 paper") and an extended description if necessary, then confirm your changes by clicking the `Commit changes` button again at the bottom right.

**5. Create a Pull Request:** Go back to your forked repository and click on `Compare & pull request`. Alternatively, select your branch from the branch selector and click `Open pull request` from the `Contribute` drop-down menu. Fill out the title and description for your pull request, and click `Create pull request` to submit it.
